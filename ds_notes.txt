zero short
few short
chain of thoughts 

The key difference between Git and GitHub is that Git is a free, open source version control tool that developers install locally on their personal computers, while GitHub is a pay-for-use online service built to run Git in the cloud.


pre tuning
fine tuning

process:
1.Data collection and storage
2.Data cleaning and preparation.
3.Model building (exploration and visualization)
4.Data evaluation(experimentation and prediction)
5.Data organization

Types of algorithms:(ML models)
1.Supervised learning
2.Unsupervised learning(unlabelled data,we do not train this model)
3.Reinforcement learning
4.Semi-supervised learning

supervised learning:
types:
linear 
logistic
support vector
k nearest
decision tree
random forest technique



import numpy as np
import pandas as pd
impot matplotlib.pyplot as plt
import seaborn as sns

GitHub:
created a new data science folder
commands in gitbash:
cd Desktop/
git clone repository link 
cd folder_name
git config --global user.email "your email"
git config ==global user.name "your name"
cd repository_name
git add .
git status
git commit -m "changes of file added"
git push
git pull  

SQL:
Database is a logical,consistent and organized collection of related data that can be easily accessed,managed and updated.The main purpose is to operate large information of data(information)by storing,retrieving and managing data.DBMS is a software which is used to interact with the database.RDBMS organizes data into a table based data structure with a strict,predefined schema required.DBMS is a software that allows user to create  and maintain a database. 
Database architecture:
1.1-Tier architecture:Both UI &CPU in one system.(Accessing from the same system.)
2.2-Tier architecture:The UI will be in one machine.(The UI in one machine and DBMS in another machine)
3.3-Tier architecture:There will be one UI and multiple machines.(Multiple UI,Multiple DBMS,Multiple systems)

SQL COMMANDS:
1.DDL-Data Defintion Language(Create,Alter,Drop,Truncate)
2.DML-Data Manipulation Language(Insert,Update,Delete)
3.DCL-Data Control Language(Grant,Revoke)
4.TCL-Transaction Control Language(Commit,Rollback)
5.DQL-Data Query Language(Select)


1.\L-TO VIEW A DATABASE
2.\dt-to view a table in a database
3.create database database_name
4.\d-to display a table
5.\c-to connect a database to a table
6.create table table_name(var_name_1 var_type,var_name_2,var_type);
7.insert into table_name values(arg_1,arg_2);
8.select * from table_name;-to view the data inserted in the table
9.alter table table_name add var_name_3 var_type;
10.ALTER TABLE Table_name DROP COLUMN column_name;
11.UPDATE table_name SET Column_name WHERE unique key value;
12.select * from table_name ORDER BY column_name (or) desc;
13.SELECT column_name(s) FROM table_name WHERE column_name IN (value1, value2, ...);
14.SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2;

Aggregate functions:

sum()

AVG()

Min()

Max()

Count()

Join:
Syntax:
Select common_column_name from table_1 Inner join table_2 on table_1.common_column_name=table2.common_column_name

Joins:

1.Inner Join

2.Outer Join- 1.left outer join

               2.right outer join

3.Self Join


select (emp_id,dep,sal),RANK() OVER(PARTITION BY dep ORDER BY sal DESC) AS rank
FROM aids;-Rank query

select (emp_id,dep,sal),DENSE_RANK() OVER(PARTITION BY dep ORDER BY sal DESC) AS denserank
FROM aids;=Dense rank query

select (emp_id,dep,sal),row_number() OVER(PARTITION BY dep ORDER BY sal DESC) AS rownum
FROM aids;-

The reason why we use postgre_sql over MySQL is that we can store all types of data,and it has higherÂ accessibility.

Web Scraping:

To extract data from websites.
Beautiful shape-a library in python(illegal tool)(static webs)
Selenium-for dynamic websites.(illegal tool)
API-legal tool(much faster than the other two)
To generate Youtube API key(google developer console)
Google Youtube API documentation
To Scrap channel statistics from Youtube
Analyse and visualise the Youtube channel
Scrap video details for a youtube channel(task)
Scrap using beautiful soup and selenium(task)

Linear Regression:(Formula)
1/1-e^-z

Outlayers-Unstructured data(data that exists beyond a certain range)
To make it a structured data,we use mean,median and mode.

Correlation analysis-Feature Selection:
This would check the input and the output which is influenced more upon by each other.We use the highly influenced element.

Input-Independent parameter
Output=Dependent parameter

Data Scaling:

To arrange the data all at once.
1.Standard Scaling 
2.Minmax Scaling(-1 to 1)
3.Robust Scaling

This all comes under preprocessing.(scaling,correlation etc)

Unsupervised learning:(clustering)
1.Hierachical
2.k-means
3.DBSCAN 
4.Principle compound analysis.

Semi-supervised learning:
Semi-supervised learning utilizes both labeled and unlabeled data to train models, offering a balance between supervised and unsupervised learning techniques. Common approaches include self-training, co-training, and graph-based methods. 